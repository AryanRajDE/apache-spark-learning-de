{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccc74c36-cd37-45c0-b020-272a694408f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "This notebook shows how to read and write the data in pyspark via Dataframe API using different ways and options.\n",
    "\n",
    "#### **Contents :**\n",
    "- Reading file via `DataFrameReader.json()` method \n",
    "- Reading file via `DataFrameReader.format().load()` method \n",
    "- Writing file via `DataframeWriter.write().json()` method \n",
    "- Writing file via `DataframeWriter.write().format().save()` method \n",
    "\n",
    "This is a **Python** notebook so the default cell type is Python. However, you can use different languages by using the %LANGUAGE magic command. `Python`, `Scala(%scala)`, `SQL(%sql)`, `FileStore(%fs)` and `R(%r)` all are supported.\n",
    "\n",
    "**Input JSON File Used :** \n",
    "- https://github.com/databricks/Spark-The-Definitive-Guide/blob/master/data/flight-data/json/2011-summary.json\n",
    "\n",
    "**Spark Read/Write Documentation Link**\n",
    "- https://spark.apache.org/docs/latest/sql-data-sources.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9aca0e-144d-47b2-b9ef-77940d36a1f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: [FileInfo(path='dbfs:/FileStore/tables/2010_summary.csv', name='2010_summary.csv', size=7121, modificationTime=1728547018000),\n FileInfo(path='dbfs:/FileStore/tables/2010_summary_write/', name='2010_summary_write/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/2010_summary_write.csv/', name='2010_summary_write.csv/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/2010_summary_write_02/', name='2010_summary_write_02/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/2011_summary.json', name='2011_summary.json', size=21301, modificationTime=1729515377000),\n FileInfo(path='dbfs:/FileStore/tables/2011_summary_write.json/', name='2011_summary_write.json/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/NewFile/', name='NewFile/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/RangeFile/', name='RangeFile/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/RangeText/', name='RangeText/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/RangeText.txt/', name='RangeText.txt/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/SparkText', name='SparkText', size=1761, modificationTime=1728552324000),\n FileInfo(path='dbfs:/FileStore/tables/SparkText.txt', name='SparkText.txt', size=513, modificationTime=1728828118000)]"
     ]
    }
   ],
   "source": [
    "# check the files under FileStore\n",
    "dbutils.fs.ls('FileStore/tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1db1cbc3-cd32-4f4e-b02d-9545de2931b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Reading file via `DataFrameReader.json()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ade43fd2-e7a7-4bc0-8a21-dbe015c9e748",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>Saint Martin</td><td>2</td></tr><tr><td>United States</td><td>Guinea</td><td>2</td></tr><tr><td>United States</td><td>Croatia</td><td>1</td></tr><tr><td>United States</td><td>Romania</td><td>3</td></tr><tr><td>United States</td><td>Ireland</td><td>268</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Saint Martin",
         2
        ],
        [
         "United States",
         "Guinea",
         2
        ],
        [
         "United States",
         "Croatia",
         1
        ],
        [
         "United States",
         "Romania",
         3
        ],
        [
         "United States",
         "Ireland",
         268
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# A JSON dataset is pointed to by path.\n",
    "# The path can be either a single text file or a directory storing text files\n",
    "\n",
    "# Define read options\n",
    "options = {\n",
    "    \"inferSchema\": \"True\",\n",
    "    \"header\": \"True\",\n",
    "    \"mode\": \"FAILFAST\"\n",
    "}\n",
    "\n",
    "file_path = \"/FileStore/tables/2011_summary.json\"\n",
    "df = spark.read.options(**options).json(file_path)\n",
    "\n",
    "# Display the result dataframe \n",
    "display(df.head(5))\n",
    "display(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5170be7f-2041-4c2b-b20f-d2c8bb72b617",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Reading file via `DataFrameReader.format().load()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02410e22-738e-441e-b1c9-06a76251d993",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>Saint Martin</td><td>2</td></tr><tr><td>United States</td><td>Guinea</td><td>2</td></tr><tr><td>United States</td><td>Croatia</td><td>1</td></tr><tr><td>United States</td><td>Romania</td><td>3</td></tr><tr><td>United States</td><td>Ireland</td><td>268</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Saint Martin",
         2
        ],
        [
         "United States",
         "Guinea",
         2
        ],
        [
         "United States",
         "Croatia",
         1
        ],
        [
         "United States",
         "Romania",
         3
        ],
        [
         "United States",
         "Ireland",
         268
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/FileStore/tables/2011_summary.json\"\n",
    "file_type = \"json\"\n",
    "\n",
    "# JSON options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "\n",
    "# The applied options are for JSON files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"mode\", \"FAILFAST\") \\\n",
    "  .load(file_path)\n",
    "\n",
    "# Display the result dataframe \n",
    "display(df.head(5))\n",
    "display(df.printSchema())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c0560e7-a1fc-48c8-800c-37152eefcef1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Writing file via DataframeWriter.write().json() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0a41ca-361d-43f6-87a5-d236e3281bc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>Saint Martin</td><td>2</td></tr><tr><td>United States</td><td>Guinea</td><td>2</td></tr><tr><td>United States</td><td>Croatia</td><td>1</td></tr><tr><td>United States</td><td>Romania</td><td>3</td></tr><tr><td>United States</td><td>Ireland</td><td>268</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "Saint Martin",
         2
        ],
        [
         "United States",
         "Guinea",
         2
        ],
        [
         "United States",
         "Croatia",
         1
        ],
        [
         "United States",
         "Romania",
         3
        ],
        [
         "United States",
         "Ireland",
         268
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Read a JSON file with chaining multiple options\n",
    "df_read = spark.read.option(\"inferSchema\", True) \\\n",
    "                .option(\"header\", True) \\\n",
    "                .json(\"/FileStore/tables/2011_summary.json\")\n",
    "\n",
    "# Display the result dataframe \n",
    "display(df_read.head(5))\n",
    "display(df_read.printSchema())\n",
    "\n",
    "# Save and Write DataFrame to JSON File via write().csv() method \n",
    "df_read.write.option(\"header\",True) \\\n",
    "               .mode('ignore') \\\n",
    "               .option(\"compression\", \"gzip\") \\\n",
    "               .json(\"/FileStore/tables/2011_summary_write.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab6299e3-4844-49c2-b74d-60040a92f526",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Writing file via DataframeWriter.write().format().save() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe6d112-0ec2-45fd-93a7-6989be3ff335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DEST_COUNTRY_NAME</th><th>ORIGIN_COUNTRY_NAME</th><th>count</th></tr></thead><tbody><tr><td>United States</td><td>India</td><td>76</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "United States",
         "India",
         76
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DEST_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ORIGIN_COUNTRY_NAME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read a JSON file with chaining multiple options\n",
    "df_read = spark.read.option(\"inferSchema\", True) \\\n",
    "                .option(\"header\", True) \\\n",
    "                .json(\"/FileStore/tables/2011_summary.json\")\n",
    "\n",
    "# Display the result dataframe \n",
    "df_less = df_read.where(df_read.ORIGIN_COUNTRY_NAME=='India')\n",
    "display(df_less)\n",
    "\n",
    "# Save and Write DataFrame to CSV File via format().save() method\n",
    "df_less.write.format(\"json\").option(\"header\",True) \\\n",
    "                .mode('overwrite') \\\n",
    "                .option(\"compression\", \"gzip\") \\\n",
    "                .save(\"/FileStore/tables/2011_summary_write.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce527b63-8468-4610-9ede-3ea2ebc291b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creates a temporary view using the DataFrame\n",
    "peopleDF.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# SQL statements can be run by using the sql methods provided by spark\n",
    "teenagerNamesDF = spark.sql(\"SELECT name FROM people WHERE age BETWEEN 13 AND 19\")\n",
    "teenagerNamesDF.show()\n",
    "# +------+\n",
    "# |  name|\n",
    "# +------+\n",
    "# |Justin|\n",
    "# +------+\n",
    "\n",
    "# Alternatively, a DataFrame can be created for a JSON dataset represented by\n",
    "# an RDD[String] storing one JSON object per string\n",
    "jsonStrings = ['{\"name\":\"Yin\",\"address\":{\"city\":\"Columbus\",\"state\":\"Ohio\"}}']\n",
    "otherPeopleRDD = sc.parallelize(jsonStrings)\n",
    "otherPeople = spark.read.json(otherPeopleRDD)\n",
    "otherPeople.show()\n",
    "# +---------------+----+\n",
    "# |        address|name|\n",
    "# +---------------+----+\n",
    "# |[Columbus,Ohio]| Yin|\n",
    "# +---------------+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe98b57-9cf2-42cb-ad24-4df396a4452e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_read = spark.read.option(\"inferSchema\", True) \\\n",
    "                .option(\"header\", True) \\\n",
    "                .json(\"/FileStore/tables/2011_summary.json\")\n",
    "\n",
    "# Creates a temporary view using the DataFrame\n",
    "df_read.createOrReplaceTempView(\"2011Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0747425f-2480-43ee-a75d-80f50c2e3e84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|DEST_COUNTRY_NAME|\n+-----------------+\n|            Yemen|\n|             Togo|\n|       The Gambia|\n|    United States|\n|          Belarus|\n|            Malta|\n|       Mauritania|\n|          Georgia|\n|            Libya|\n|          Namibia|\n|     Saint Martin|\n|          Lebanon|\n|        Greenland|\n|          Vietnam|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL statements can be run by using the sql methods provided by spark\n",
    "dest_df = spark.sql(\"SELECT DISTINCT DEST_COUNTRY_NAME FROM 2011Summary WHERE count = 1\")\n",
    "dest_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ce079a-a341-4d92-9ebf-1adb1f06fc5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Since this table is registered as a temp view, it will only be available to this notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n",
    "# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n",
    "# To do so, choose your table name and uncomment the bottom line.\n",
    "\n",
    "permanent_table_name = \"2011_summary_table\"\n",
    "\n",
    "df.write.mode('overwrite').format('delta').saveAsTable(permanent_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb70e7cb-bb45-4f75-9b50-4410f830723b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"DEST_COUNTRY_NAME\":\"JAPAN\", \"ORIGIN_COUNTRY_NAME\":\"INDIA\", \"count\":\"7\"}']\n+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|            JAPAN|              INDIA|    7|\n+-----------------+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, a DataFrame can be created for a JSON dataset represented by\n",
    "# an RDD[String] storing one JSON object per string\n",
    "\n",
    "jsonStrings = ['{\"DEST_COUNTRY_NAME\":\"JAPAN\", \"ORIGIN_COUNTRY_NAME\":\"INDIA\", \"count\":\"7\"}']\n",
    "print(jsonStrings)\n",
    "\n",
    "otherRDD = sc.parallelize(jsonStrings)\n",
    "newRDD = spark.read.json(otherRDD)\n",
    "newRDD.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfee6b34-8cfb-4e36-9503-66c0d28305a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1818078824042964,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "readWriteJSON",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
